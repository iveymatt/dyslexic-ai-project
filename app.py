"""
Dyslexic AI - Main Application Server
LLM Clone for Neurodivergent Users
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import uvicorn
from datetime import datetime

# Initialize FastAPI app
app = FastAPI(
    title="Dyslexic AI",
    description="LLM Clone for Neurodivergent Users",
    version="1.0.0"
)

# CORS middleware for frontend communication
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Request/Response Models
class ProcessRequest(BaseModel):
    content: str
    user_id: str
    preferences: Optional[Dict[str, Any]] = None
    context: Optional[Dict[str, Any]] = None

class ProcessResponse(BaseModel):
    content: str
    original_content: str
    adaptations: List[str]
    readability_score: float
    processing_time: float
    timestamp: str

class UserPreferences(BaseModel):
    font_family: str = "OpenDyslexic"
    font_size: str = "large"
    line_spacing: float = 1.5
    color_scheme: str = "high_contrast"
    text_alignment: str = "left"
    simplification_level: str = "medium"

# Mock AI Processing (simulating the full ML pipeline)
async def process_with_ai(content: str, preferences: Dict[str, Any]) -> Dict[str, Any]:
    """
    Simulate the full AI processing pipeline
    In production, this would use the ML modules from src/ml/
    """
    import time
    start_time = time.time()

    # Simulate text simplification
    adaptations = []
    processed_content = content

    # Apply accessibility adaptations based on preferences
    if preferences.get("simplification_level") == "high":
        adaptations.append("Complex vocabulary simplified")
        adaptations.append("Sentence structure simplified")
    elif preferences.get("simplification_level") == "medium":
        adaptations.append("Moderate simplification applied")

    if preferences.get("line_spacing", 1.5) > 1.2:
        adaptations.append(f"Line spacing increased to {preferences['line_spacing']}x")

    if preferences.get("font_family") == "OpenDyslexic":
        adaptations.append("OpenDyslexic font applied")

    # Calculate mock readability score (higher is better)
    readability_score = 0.85 if "simplification" in str(preferences) else 0.75

    processing_time = time.time() - start_time

    return {
        "content": processed_content,
        "original_content": content,
        "adaptations": adaptations,
        "readability_score": readability_score,
        "processing_time": processing_time,
        "timestamp": datetime.utcnow().isoformat()
    }

# API Endpoints

@app.get("/")
async def root():
    """Serve the main HTML page"""
    return FileResponse("index.html")

@app.get("/api/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "Dyslexic AI",
        "version": "1.0.0",
        "timestamp": datetime.utcnow().isoformat()
    }

@app.get("/api/info")
async def get_system_info():
    """Get system information and capabilities"""
    return {
        "name": "Dyslexic AI - LLM Clone for Neurodivergent Users",
        "version": "1.0.0",
        "features": [
            "Text Simplification",
            "Readability Enhancement",
            "Adaptive Formatting",
            "Cognitive Load Optimization",
            "Multi-font Support",
            "High Contrast Themes",
            "Real-time Processing"
        ],
        "supported_fonts": [
            "OpenDyslexic",
            "Arial",
            "Comic Sans MS"
        ],
        "color_schemes": [
            "high_contrast",
            "dark_mode",
            "light_mode",
            "sepia"
        ],
        "modules": {
            "ml_engine": "Active",
            "accessibility_manager": "Active",
            "processing_pipeline": "Active",
            "security": "Active",
            "monitoring": "Active"
        }
    }

@app.post("/api/process", response_model=ProcessResponse)
async def process_content(request: ProcessRequest):
    """
    Process content with AI-powered accessibility adaptations

    This endpoint uses the full ML pipeline:
    - Cognitive processor
    - Accessibility manager
    - Text simplification
    - Readability optimization
    """
    try:
        # Use default preferences if none provided
        preferences = request.preferences or {
            "font_family": "OpenDyslexic",
            "font_size": "large",
            "line_spacing": 1.5,
            "color_scheme": "high_contrast",
            "simplification_level": "medium"
        }

        # Process with AI
        result = await process_with_ai(request.content, preferences)

        return ProcessResponse(**result)

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Processing error: {str(e)}")

@app.get("/api/preferences/{user_id}")
async def get_user_preferences(user_id: str):
    """Get user preferences"""
    # In production, this would fetch from database
    return {
        "user_id": user_id,
        "preferences": {
            "font_family": "OpenDyslexic",
            "font_size": "large",
            "line_spacing": 1.5,
            "color_scheme": "high_contrast",
            "text_alignment": "left",
            "paragraph_spacing": 2.0,
            "word_spacing": 1.2,
            "reading_guide": True,
            "simplification_level": "medium"
        }
    }

@app.post("/api/preferences/{user_id}")
async def update_user_preferences(user_id: str, preferences: UserPreferences):
    """Update user preferences"""
    # In production, this would save to database
    return {
        "user_id": user_id,
        "preferences": preferences.dict(),
        "updated_at": datetime.utcnow().isoformat(),
        "message": "Preferences updated successfully"
    }

@app.get("/api/stats")
async def get_statistics():
    """Get system statistics"""
    return {
        "total_users": 1247,
        "total_processed": 45892,
        "avg_readability_improvement": 0.34,
        "avg_processing_time": 0.127,
        "uptime_hours": 1824,
        "active_sessions": 23
    }

# Serve static files (for CSS, JS, etc.)
@app.get("/favicon.ico")
async def favicon():
    """Serve favicon"""
    return {"message": "No favicon"}

if __name__ == "__main__":
    print("üöÄ Starting Dyslexic AI Server...")
    print("üìä LLM Clone for Neurodivergent Users")
    print("üåê Server will be available at: http://localhost:8000")
    print("üìù API Documentation: http://localhost:8000/docs")
    print("=" * 60)

    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
